{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base feature set with advanced and mean encoded features\n",
    "df_base_adv_mean = pd.read_csv('input/feature_sets/base_adv_mean.csv')\n",
    "\n",
    "# reading the test file\n",
    "features_to_drop = ['status_group','id']\n",
    "df_test_X = pd.read_csv('input/feature_sets/base_adv_mean_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_base_adv_mean.drop(['status_group','id','functional needs repair','non functional'], axis=1)\n",
    "y = df_base_adv_mean['status_group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# a little adjustment\n",
    "df_test_X.funder_mean_nf.fillna(0, inplace=True) \n",
    "df_test_X.funder_mean_fr.fillna(0, inplace=True) \n",
    "\n",
    "######################################################################\n",
    "###        RANDOM FOREST CLASSIFIER        ###########################\n",
    "######################################################################\n",
    "\n",
    "rf_balanced = RandomForestClassifier(n_jobs=-1, \n",
    "                                     verbose=1, \n",
    "                                     bootstrap=False, \n",
    "                                     max_depth=101,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     min_samples_split=6,\n",
    "                                     n_estimators=1000\n",
    "                                    )\n",
    "\n",
    "#X = df_base_adv_mean.drop(['status_group','id','functional needs repair','non functional'], axis=1)\n",
    "#y = df_base_adv_mean['status_group'].values\n",
    "\n",
    "#rf_balanced.fit(X,y)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "\n",
    "# prediction\n",
    "rf_gs_best_mean_sub_1 = rf_best.predict(df_test_X.drop(features_to_drop, axis=1))\n",
    "\n",
    "# preparing the file\n",
    "df_test_X['status_group'] = rf_gs_best_mean_sub_1\n",
    "df_gs_best_mean_sub_2 = df_test_X[['id','status_group']]\n",
    "\n",
    "#saving the file\n",
    "df_gs_best_mean_sub_2.to_csv('submissions/balanced_with_smote.csv', index=False)\n",
    "del df_gs_best_mean_sub_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.21, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543081\n",
       "non functional             0.384242\n",
       "functional needs repair    0.072677\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base_adv_mean['status_group'].value_counts()/len(df_base_adv_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "undersample = RandomUnderSampler()\n",
    "steps = [('os',oversample), ('u', undersample)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train_balanced, y_train_balanced = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25469, 25469, 25469)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_balanced[y_train_balanced=='functional']),\\\n",
    "len(y_train_balanced[y_train_balanced=='non functional']),len(y_train_balanced[y_train_balanced=='functional needs repair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### halving grid search cv - 1 (re-test 2) after applying class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date and time = 04/09/2021 02:04:37\n"
     ]
    }
   ],
   "source": [
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'max_depth' : [101,151],    \n",
    "    'min_samples_split' : [3,4],\n",
    "    'min_samples_leaf' : [2],    \n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = HalvingGridSearchCV(estimator=rfgs,param_grid=pgrid,cv=cv_skf,n_jobs=-1,verbose=10, scoring='accuracy',random_state=0)\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 25469\n",
      "max_resources_: 76407\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 4\n",
      "n_resources: 25469\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 76407\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n",
      "fd is '5'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search = cv.fit(X_train_balanced,y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 101, 'min_samples_leaf': 2, 'min_samples_split': 4}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying the class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight(labels_dict,mu=0.15):\n",
    "    total = np.sum(list(labels_dict.values()))\n",
    "    keys = labels_dict.keys()\n",
    "    weight = dict()\n",
    "    for i in keys:\n",
    "            #score = np.log(mu*total/float(labels_dict[i]))\n",
    "            #score = total/float(labels_dict[i])\n",
    "            score = float(labels_dict[i])/total\n",
    "            weight[i] = score if score > 1 else 1\n",
    "    return weight\n",
    "\n",
    "# random labels_dict\n",
    "labels_dict = df_base_adv_mean['status_group'].value_counts().to_dict()\n",
    "weights = class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_balanced = RandomForestClassifier(n_jobs=-1, \n",
    "                                     verbose=1, \n",
    "                                     bootstrap=True, \n",
    "                                     max_depth=101,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     min_samples_split=6,\n",
    "                                     n_estimators=1000,\n",
    "                                     class_weight=weights #'balanced_subsample' #balanced, balanced_subsample\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   20.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.82      0.89      0.85      6790\n",
      "functional needs repair       0.54      0.35      0.43       885\n",
      "         non functional       0.84      0.79      0.82      4799\n",
      "\n",
      "               accuracy                           0.81     12474\n",
      "              macro avg       0.73      0.68      0.70     12474\n",
      "           weighted avg       0.81      0.81      0.81     12474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_best = rf_balanced#search.best_estimator_\n",
    "rf_best.fit(X_train,y_train)\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cr = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_balanced = BalancedRandomForestClassifier(n_jobs=-1, \n",
    "                                     verbose=1, \n",
    "                                     bootstrap=True, \n",
    "                                     max_depth=101,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     min_samples_split=6,\n",
    "                                     n_estimators=1000,\n",
    "                                     class_weight='balanced_subsample'                                         \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   26.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.85      0.70      0.77      6790\n",
      "functional needs repair       0.26      0.79      0.39       885\n",
      "         non functional       0.85      0.74      0.79      4799\n",
      "\n",
      "               accuracy                           0.72     12474\n",
      "              macro avg       0.65      0.74      0.65     12474\n",
      "           weighted avg       0.81      0.72      0.75     12474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_best = rf_balanced#search.best_estimator_\n",
    "rf_best.fit(X_train,y_train)\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cr = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = pd.DataFrame(np.c_[y_test, rfpred], columns=['test','pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional        69\n",
       "non functional    53\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation[(df_validation['test']=='functional needs repair') & (df_validation['test']!=df_validation['pred'])].pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional needs repair    763\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation[(df_validation['test']=='functional needs repair') & (df_validation['test']==df_validation['pred'])].pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "437+137+311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.85875706214689"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((437+137)*100)/885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'functional': 0.543080808080808, 'non functional': 0.3842424242424242, 'functional needs repair': 0.07267676767676767}\n"
     ]
    }
   ],
   "source": [
    "def class_weight(labels_dict,mu=0.15):\n",
    "    total = np.sum(list(labels_dict.values()))\n",
    "    keys = labels_dict.keys()\n",
    "    weight = dict()\n",
    "    for i in keys:\n",
    "            score = float(labels_dict[i])/total\n",
    "            weight[i] = score if score < 1 else 1\n",
    "    return weight\n",
    "\n",
    "# random labels_dict\n",
    "labels_dict = df_base_adv_mean['status_group'].value_counts().to_dict()\n",
    "weights = class_weight(labels_dict)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = df_base_adv_mean['status_group'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'functional': 32259, 'non functional': 22824, 'functional needs repair': 4317}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.286622832593781\n",
      "-0.9406383724284809\n",
      "0.7246135249093774\n"
     ]
    }
   ],
   "source": [
    "mu=0.15\n",
    "total = np.sum(list(labels_dict.values()))\n",
    "keys = labels_dict.keys()\n",
    "for i in keys:\n",
    "    score = np.log(mu*total/float(labels_dict[i]))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543081\n",
       "non functional             0.384242\n",
       "functional needs repair    0.072677\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base_adv_mean['status_group'].value_counts()/len(df_base_adv_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59400"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list(labels_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([32259, 22824, 4317])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59400"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_base_adv_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
