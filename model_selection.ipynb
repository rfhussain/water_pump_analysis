{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Random Forest (Model Selection - 1)\n",
    "\n",
    "- Read the Best Selected Feature Set\n",
    "- Optimize the Random Forest with the best Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print ('Current Starting Time is : ',start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save classification report\n",
    "def classification_report_csv(report,classifier_name,ascore):\n",
    "    report_data = []\n",
    "    counter=0\n",
    "    lines = report.split('\\n')\n",
    "    \n",
    "    for line in lines[2:-5]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        \n",
    "        \n",
    "        row['classifier'] = classifier_name\n",
    "        row['accuracy_score'] = ascore\n",
    "        \n",
    "        if counter==0:\n",
    "            row['class'] = row_data[2].strip()\n",
    "            row['precision'] = float(row_data[3].strip())\n",
    "            row['recall'] = float(row_data[4].strip())\n",
    "            row['f1_score'] = float(row_data[5].strip())\n",
    "            row['accuracy_score'] = ascore\n",
    "        elif counter==1:\n",
    "            row['class'] = row_data[0].strip()\n",
    "            row['precision'] = float(row_data[1].strip())\n",
    "            row['recall'] = float(row_data[2].strip())\n",
    "            row['f1_score'] = float(row_data[3].strip())\n",
    "            row['accuracy_score'] = ascore\n",
    "        elif counter==2:\n",
    "            row['class'] = row_data[1].strip()\n",
    "            row['precision'] = float(row_data[2].strip())\n",
    "            row['recall'] = float(row_data[3].strip())\n",
    "            row['f1_score'] = float(row_data[4].strip())\n",
    "        \n",
    "        report_data.append(row)\n",
    "        \n",
    "        counter+=1\n",
    "        \n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "        \n",
    "    if os.path.exists('classification_reports/classification_report.csv'):\n",
    "        df_cr = pd.read_csv('classification_reports/classification_report.csv')\n",
    "                \n",
    "        t = df_cr[df_cr['classifier']==classifier_name].index\n",
    "        if len(t)>0:\n",
    "            df_cr.drop(t, inplace=True)\n",
    "        \n",
    "        df_cr = pd.concat([df_cr,dataframe])\n",
    "        df_cr.to_csv('classification_reports/classification_report.csv', index = False)\n",
    "    else:\n",
    "        dataframe.to_csv('classification_reports/classification_report.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reading all the feature set files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base feature set with advanced and mean encoded features\n",
    "df_base_adv_mean = pd.read_csv('input/feature_sets/base_adv_mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model with Base + Advanced + Mean Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_base_adv_mean.drop(['status_group','id','functional needs repair','non functional'], axis=1)\n",
    "y = df_base_adv_mean['status_group'].values\n",
    "\n",
    "# i have changed below to test size .21 based on results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.21, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**verifying the results as were during the feature set selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rf object\n",
    "rf_base = RandomForestClassifier(n_estimators=101, n_jobs=-1)\n",
    "\n",
    "# fit the same base model\n",
    "rf_clf = rf_base.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "rf_clf_pred = rf_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "fig, axes = plt.subplots(figsize=(19,11))\n",
    "\n",
    "matrix = plot_confusion_matrix(rf_clf, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true',ax= axes)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show(matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_clf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving Search CV-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'max_depth' : [51,None],    \n",
    "    'min_samples_split' : [5,6],\n",
    "    'min_samples_leaf' : [1,2],    \n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = HalvingGridSearchCV(estimator=rfgs,param_grid=pgrid,cv=cv_skf,n_jobs=-1,verbose=10, scoring='accuracy',random_state=0)\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**executing the halving grid search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/HalvingGridSearchCV.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/HalvingGridSearchCV.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cr = print(classification_report(y_test, rfpred))\n",
    "print(cr)\n",
    "classification_report_csv(cr,'HalvingGridSearchCV.pkl',accuracy_score(y_test, rfpred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving Search CV - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'max_depth' : [51,None],    \n",
    "    'min_samples_split' : [5,6],\n",
    "    'min_samples_leaf' : [1,2],    \n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = HalvingGridSearchCV(\n",
    "    estimator=rfgs,param_grid=pgrid,cv=cv_skf,n_jobs=-1,verbose=10,scoring='balanced_accuracy',random_state=0,\n",
    "    resource='n_estimators',max_resources=1000)\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**executing the halving grid search cv-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/HalvingGridSearchCV_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/HalvingGridSearchCV_2.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cr = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)\n",
    "classification_report_csv(cr,'HalvingGridSearchCV_2.pkl',accuracy_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving Search CV - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'n_estimators':[451,751],\n",
    "    'min_samples_split' : [5,6],\n",
    "    'min_samples_leaf' : [1,2],    \n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = HalvingGridSearchCV(\n",
    "    estimator=rfgs,param_grid=pgrid,cv=cv_skf,n_jobs=-1,verbose=10,scoring='accuracy',random_state=0,\n",
    "    resource='max_depth',max_resources=150)\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**executing the halving grid search cv-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/HalvingGridSearchCV_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/HalvingGridSearchCV_3.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cv = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)\n",
    "\n",
    "classification_report_csv(cr,'HalvingGridSearchCV_3.pkl',accuracy_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Grid Search -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'max_depth' : [51,None],    \n",
    "    'max_features' : ['sqrt','log2'],\n",
    "    'min_samples_split' : [5,6],\n",
    "    'min_samples_leaf' : [1,2,3],\n",
    "    'criterion' : ['gini','entropy']    \n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = RandomizedSearchCV(estimator=rfgs,param_distributions=pgrid,cv=cv_skf,n_jobs=-1, \n",
    "                        verbose=10, scoring='accuracy',random_state=0)\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**executing the randomized grid search cv-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/RandomizedSearchCV.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/RandomizedSearchCV.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cv = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)\n",
    "\n",
    "classification_report_csv(cr,'RandomizedSearchCV.pkl',accuracy_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Grid Search - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'n_estimators': [451,751,1000,1100],\n",
    "    'max_depth' : [51,None],    \n",
    "    'min_samples_split' : [3,5],\n",
    "    'min_samples_leaf' : [1,2],\n",
    "    'criterion' : ['gini','entropy']  \n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = RandomizedSearchCV(estimator=rfgs,param_distributions=pgrid,cv=cv_skf,n_jobs=-1,verbose=10,\n",
    "                        scoring='balanced_accuracy',random_state=0)\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**executing the randomized grid search cv-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/RandomizedSearchCV_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/RandomizedSearchCV_2.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cv = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)\n",
    "\n",
    "classification_report_csv(cr,'RandomizedSearchCV_2.pkl',accuracy_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "pgrid = {\n",
    "    'n_estimators'      : [451,1001],\n",
    "    'bootstrap'         : [True,False],\n",
    "    'criterion'         : ['gini','entropy'],\n",
    "    'max_depth'         : [21,51],        \n",
    "    'min_samples_split' : [2,3,5],\n",
    "    'min_samples_leaf'  : [1,2,3]\n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_ss = StratifiedShuffleSplit(n_splits=3, train_size=0.75, test_size=.25,random_state=0)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = GridSearchCV(estimator=rfgs, param_grid=pgrid, cv=cv_ss, n_jobs=-1, verbose=10, scoring='accuracy')\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**execute grid search 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/GridSearchCV.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/GridSearchCV.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cv = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)\n",
    "\n",
    "classification_report_csv(cr,'GridSearchCV.pkl',accuracy_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid \n",
    "pgrid = {\n",
    "    'n_estimators' : [451,751],\n",
    "    'max_depth' : [51,None],    \n",
    "    'max_features' : ['sqrt','log2','auto'],\n",
    "    'min_samples_split' : [5,6],\n",
    "    'min_samples_leaf' : [1,2,3],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False) # need to change to 3 splits based on results\n",
    "\n",
    "# specifying the model \n",
    "rfgs = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "\n",
    "# keep track of the date and time\n",
    "dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = GridSearchCV(estimator=rfgs, param_grid=pgrid, cv=cv_skf, n_jobs=-1, verbose=10, scoring='balanced_accuracy')\n",
    "\n",
    "# pring the date and time \n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**execuate the grid search - 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "joblib.dump(cv.fit(X_train,y_train),'models/GridSearchCV_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**display the best param**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_cv = joblib.load('models/GridSearchCV_2.pkl')\n",
    "loaded_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get the best estimator model and execute predictions on it, along with the classification score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = loaded_cv.best_estimator_\n",
    "\n",
    "# get the prediction\n",
    "rfpred = rf_best.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "cv = classification_report(y_test, rfpred)\n",
    "\n",
    "print(cr)\n",
    "\n",
    "classification_report_csv(cr,'GridSearchCV_2.pkl',accuracy_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the Results - Sorted by Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cr = pd.read_csv('classification_reports/classification_report.csv')\n",
    "df_cr[['classifier','accuracy_score']].drop_duplicates().sort_values(by='accuracy_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print ('Current Starting Time is : ',end_time)\n",
    "c = end_time - start_time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The execution ended after {} minutes'.format(c.seconds/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
